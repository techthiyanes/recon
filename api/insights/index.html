
<!DOCTYPE html>

<html class="no-js" lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width,initial-scale=1" name="viewport"/>
<meta content="Debug annotated Named Entity Recognition (NER) data for inconsitencies and get insights on improving the quality of your data." name="description"/>
<link href="https://microsoft.github.io/reconner/api/insights/" rel="canonical"/>
<link href="../../img/favicon.ico" rel="shortcut icon"/>
<meta content="mkdocs-1.1.2, mkdocs-material-5.4.0" name="generator"/>
<title>Insights - Recon</title>
<link href="../../assets/stylesheets/main.fe0cca5b.min.css" rel="stylesheet"/>
<link href="../../assets/stylesheets/palette.a46bcfb3.min.css" rel="stylesheet"/>
<meta content="#2196f3" name="theme-color"/>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&amp;display=fallback" rel="stylesheet"/>
<style>body,input{font-family:"Roboto",-apple-system,BlinkMacSystemFont,Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono",SFMono-Regular,Consolas,Menlo,monospace}</style>
<link href="../../css/termynal.css" rel="stylesheet"/>
<link href="../../css/custom.css" rel="stylesheet"/>
<meta content="https://microsoft.github.io/reconner/api/insights/" property="og:url"/>
<meta content="Insights - Recon" property="og:title"/>
<meta content="Debug annotated Named Entity Recognition (NER) data for inconsitencies and get insights on improving the quality of your data." property="og:description"/>
<meta content="https://microsoft.github.io/reconner/img/recon.svg" property="og:image"/>
<meta content="Recon NER" property="og:image:alt"/>
<meta content="summary_large_image" name="twitter:card"/>
<meta content="@kabir_khan14" name="twitter:site"/>
<meta content="@kabir_khan14" name="twitter:creator"/>
<meta content="Insights - Recon" property="twitter:title"/>
<meta content="Debug annotated Named Entity Recognition (NER) data for inconsitencies and get insights on improving the quality of your data." name="twitter:description"/>
<meta content="https://microsoft.github.io/reconner/img/recon.svg" name="twitter:image"/>
<meta content="Recon NER" name="twitter:image:alt"/>
</head>
<body data-md-color-accent="blue" data-md-color-primary="blue" data-md-color-scheme="" dir="ltr">
<input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/>
<input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/>
<label class="md-overlay" for="__drawer"></label>
<div data-md-component="skip">
<a class="md-skip" href="#recon.insights">
          Skip to content
        </a>
</div>
<div data-md-component="announce">
</div>
<header class="md-header" data-md-component="header">
<nav aria-label="Header" class="md-header-nav md-grid">
<a aria-label="Recon" class="md-header-nav__button md-logo" href="https://microsoft.github.io/reconner/" title="Recon">
<img alt="logo" src="../../img/drone-white.svg"/>
</a>
<label class="md-header-nav__button md-icon" for="__drawer">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"></path></svg>
</label>
<div class="md-header-nav__title" data-md-component="header-title">
<div class="md-header-nav__ellipsis">
<span class="md-header-nav__topic md-ellipsis">
            Recon
          </span>
<span class="md-header-nav__topic md-ellipsis">
            
              Insights
            
          </span>
</div>
</div>
<div class="md-header-nav__source">
<a class="md-source" href="https://github.com/microsoft/reconner/" title="Go to repository">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 00-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 01-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 000 40.81l195.61 195.6a28.86 28.86 0 0040.8 0l194.69-194.69a28.86 28.86 0 000-40.81z"></path></svg>
</div>
<div class="md-source__repository">
    microsoft/reconner
  </div>
</a>
</div>
</nav>
</header>
<div class="md-container" data-md-component="container">
<main class="md-main" data-md-component="main">
<div class="md-main__inner md-grid">
<div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="Navigation" class="md-nav md-nav--primary" data-md-level="0">
<label class="md-nav__title" for="__drawer">
<a aria-label="Recon" class="md-nav__button md-logo" href="https://microsoft.github.io/reconner/" title="Recon">
<img alt="logo" src="../../img/drone-white.svg"/>
</a>
    Recon
  </label>
<div class="md-nav__source">
<a class="md-source" href="https://github.com/microsoft/reconner/" title="Go to repository">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 00-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 01-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 000 40.81l195.61 195.6a28.86 28.86 0 0040.8 0l194.69-194.69a28.86 28.86 0 000-40.81z"></path></svg>
</div>
<div class="md-source__repository">
    microsoft/reconner
  </div>
</a>
</div>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../.." title="Recon">
      Recon
    </a>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="nav-2" id="nav-2" type="checkbox"/>
<label class="md-nav__link" for="nav-2">
      Tutorial
      <span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"></path></svg>
</span>
</label>
<nav aria-label="Tutorial" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="nav-2">
<span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"></path></svg>
</span>
        Tutorial
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../tutorial/1_loading_data/" title="Loading your data">
      Loading your data
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../tutorial/2_ner_stats/" title="NER Stats">
      NER Stats
    </a>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="nav-2-3" id="nav-2-3" type="checkbox"/>
<label class="md-nav__link" for="nav-2-3">
      Dataset
      <span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"></path></svg>
</span>
</label>
<nav aria-label="Dataset" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="nav-2-3">
<span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"></path></svg>
</span>
        Dataset
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../tutorial/3_dataset_intro/" title="Introduction">
      Introduction
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../tutorial/3_dataset_mutate/" title="Making changes to a Dataset">
      Making changes to a Dataset
    </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../tutorial/4_corpus/" title="Using a Corpus">
      Using a Corpus
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../tutorial/4_more_stats/" title="More NER Stats">
      More NER Stats
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../tutorial/5_getting_insights/" title="Getting Insights">
      Getting Insights
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../tutorial/custom_entity_recognizer/" title="Custom EntityRecognizer">
      Custom EntityRecognizer
    </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" data-md-toggle="nav-3" id="nav-3" type="checkbox"/>
<label class="md-nav__link" for="nav-3">
      API Reference
      <span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"></path></svg>
</span>
</label>
<nav aria-label="API Reference" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="nav-3">
<span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"></path></svg>
</span>
        API Reference
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../corpus/" title="Corpus">
      Corpus
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../corrections/" title="Corrections">
      Corrections
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../dataset/" title="Dataset">
      Dataset
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../hashing/" title="Hashing">
      Hashing
    </a>
</li>
<li class="md-nav__item md-nav__item--active">
<input class="md-nav__toggle md-toggle" data-md-toggle="toc" id="__toc" type="checkbox"/>
<a class="md-nav__link md-nav__link--active" href="./" title="Insights">
      Insights
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../loaders/" title="Loaders">
      Loaders
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../operations/" title="Operations">
      Operations
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../stats/" title="Stats">
      Stats
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../store/" title="Store">
      Store
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../tokenization/" title="Tokenization">
      Tokenization
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../validation/" title="Validation">
      Validation
    </a>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="nav-3-12" id="nav-3-12" type="checkbox"/>
<label class="md-nav__link" for="nav-3-12">
      Recognizers
      <span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"></path></svg>
</span>
</label>
<nav aria-label="Recognizers" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="nav-3-12">
<span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"></path></svg>
</span>
        Recognizers
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../recognizers/base/" title="EntityRecognizer">
      EntityRecognizer
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../recognizers/spacy/" title="SpacyEntityRecognizer">
      SpacyEntityRecognizer
    </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../types/example/" title="Types">
      Types
    </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../contributing/" title="Development - Contributing">
      Development - Contributing
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../release-notes/" title="Release Notes">
      Release Notes
    </a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="Table of contents" class="md-nav md-nav--secondary">
</nav>
</div>
</div>
</div>
<div class="md-content">
<article class="md-content__inner md-typeset">
<a class="md-content__button md-icon" href="https://github.com/microsoft/reconner/tree/master/docs/api/insights.md" title="Edit this page">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"></path></svg>
</a>
<div class="doc doc-object doc-module">
<h2 class="hidden-toc" href="#recon.insights" id="recon.insights" style="visibility: hidden; width: 0; height: 0;">
<a class="headerlink" href="#recon.insights" title="Permanent link">¶</a></h2>
<div class="doc doc-contents first">
<div class="doc doc-children">
<div class="doc doc-object doc-function">
<h2 class="doc doc-heading" id="recon.insights.get_annotation_labels">
<code class="highlight language-python">
get_annotation_labels<span class="p">(</span><span class="n">examples</span><span class="p">,</span> <span class="n">case_sensitive</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> </code>
<a class="headerlink" href="#recon.insights.get_annotation_labels" title="Permanent link">¶</a></h2>
<div class="doc doc-contents">
<p>Constructs a map of each annotation in the list of examples to each label that annotation
has and references all examples associated with that label.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>examples</code></td>
<td><code>List[recon.types.Example]</code></td>
<td>
<p>Input examples</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>case_sensitive</code></td>
<td><code>bool</code></td>
<td>
<p>Consider case of text for each annotation</p>
</td>
<td><code>False</code></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Dict[str, Dict[str, list]]</code></td>
<td>
<p>Dict[str, Dict[str, list]]: Annotation map</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>recon/insights.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">get_annotation_labels</span><span class="p">(</span>
    <span class="n">examples</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Example</span><span class="p">],</span> <span class="n">case_sensitive</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">list</span><span class="p">]]:</span>
    <span class="sd">"""Constructs a map of each annotation in the list of examples to each label that annotation</span>
<span class="sd">    has and references all examples associated with that label.</span>

<span class="sd">    Args:</span>
<span class="sd">        examples (List[Example]): Input examples</span>
<span class="sd">        case_sensitive (bool, optional): Consider case of text for each annotation</span>

<span class="sd">    Returns:</span>
<span class="sd">        Dict[str, Dict[str, list]]: Annotation map</span>
<span class="sd">    """</span>
    <span class="n">annotation_labels_map</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">list</span><span class="p">]]</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">examples</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">e</span><span class="o">.</span><span class="n">spans</span><span class="p">:</span>
            <span class="n">text</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="n">text</span> <span class="k">if</span> <span class="n">case_sensitive</span> <span class="k">else</span> <span class="n">s</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
            <span class="n">annotation_labels_map</span><span class="p">[</span><span class="n">text</span><span class="p">][</span><span class="n">s</span><span class="o">.</span><span class="n">label</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">annotation_labels_map</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h2 class="doc doc-heading" id="recon.insights.get_ents_by_label">
<code class="highlight language-python">
get_ents_by_label<span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">case_sensitive</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> </code>
<a class="headerlink" href="#recon.insights.get_ents_by_label" title="Permanent link">¶</a></h2>
<div class="doc doc-contents">
<p>Get a dictionary of unique text spans by label for your data</p>
<h1 id="todo-ok-so-this-needs-to-return-more-than-just-a-set-for-each-label">TODO: Ok so this needs to return more than just a set for each label.<a class="headerlink" href="#todo-ok-so-this-needs-to-return-more-than-just-a-set-for-each-label" title="Permanent link">¶</a></h1>
<p>We want to return a dictionary that maps labels to AnnotationCount objects where each
AnnotationCount contains the text of the annotation text, the total number of times it's mentioned (e.g. what entity_coverage does)
but also the examples it is in.</p>
<p>So maybe I can get this info from entity_coverage? IDK but this is dumb rn and not very flexible.</p>
<p>Maybe I should keep this function returning a set of strings for each label for compatability but I need the other way too
so I know what to focus on in editing and a</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>data</code></td>
<td><code>List[recon.types.Example]</code></td>
<td>
<p>List of examples</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>case_sensitive</code></td>
<td><code>bool</code></td>
<td>
<p>Consider case of text for each annotation</p>
</td>
<td><code>False</code></td>
</tr>
<tr>
<td><code>sort_by</code></td>
<td><code>SortBy</code></td>
<td>
<p>Sort by text or by count</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>DefaultDict[str, List[str]]</code></td>
<td>
<p>DefaultDict[str, List[str]]: DefaultDict mapping label to sorted list of the unique
    spans annotated for that label.</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>recon/insights.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">get_ents_by_label</span><span class="p">(</span>
    <span class="n">data</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Example</span><span class="p">],</span> <span class="n">case_sensitive</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DefaultDict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]:</span>
    <span class="sd">"""Get a dictionary of unique text spans by label for your data</span>

<span class="sd">    # TODO: Ok so this needs to return more than just a set for each label.</span>

<span class="sd">    We want to return a dictionary that maps labels to AnnotationCount objects where each</span>
<span class="sd">    AnnotationCount contains the text of the annotation text, the total number of times it's mentioned (e.g. what entity_coverage does)</span>
<span class="sd">    but also the examples it is in.</span>

<span class="sd">    So maybe I can get this info from entity_coverage? IDK but this is dumb rn and not very flexible.</span>

<span class="sd">    Maybe I should keep this function returning a set of strings for each label for compatability but I need the other way too</span>
<span class="sd">    so I know what to focus on in editing and a</span>

<span class="sd">    Args:</span>
<span class="sd">        data (List[Example]): List of examples</span>
<span class="sd">        case_sensitive (bool, optional): Consider case of text for each annotation</span>
<span class="sd">        sort_by (SortBy): Sort by text or by count</span>

<span class="sd">    Returns:</span>
<span class="sd">        DefaultDict[str, List[str]]: DefaultDict mapping label to sorted list of the unique</span>
<span class="sd">            spans annotated for that label.</span>
<span class="sd">    """</span>
    <span class="n">annotations</span><span class="p">:</span> <span class="n">DefaultDict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Set</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">set</span><span class="p">)</span>
    <span class="n">sorted_annotations</span><span class="p">:</span> <span class="n">DefaultDict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">e</span><span class="o">.</span><span class="n">spans</span><span class="p">:</span>
            <span class="n">span_text</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="n">text</span> <span class="k">if</span> <span class="n">case_sensitive</span> <span class="k">else</span> <span class="n">s</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
            <span class="n">annotations</span><span class="p">[</span><span class="n">s</span><span class="o">.</span><span class="n">label</span><span class="p">]</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">span_text</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">label</span><span class="p">,</span> <span class="n">anns</span> <span class="ow">in</span> <span class="n">annotations</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">sorted_annotations</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">anns</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">sorted_annotations</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h2 class="doc doc-heading" id="recon.insights.get_hardest_examples">
<code class="highlight language-python">
get_hardest_examples<span class="p">(</span><span class="n">pred_errors</span><span class="p">,</span> <span class="n">return_pred_errors</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_pred_error_examples</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> </code>
<a class="headerlink" href="#recon.insights.get_hardest_examples" title="Permanent link">¶</a></h2>
<div class="doc doc-contents">
<p>Get hardest examples from list of PredictionError types</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>pred_errors</code></td>
<td><code>List[recon.types.PredictionError]</code></td>
<td>
<p>list of PredictionError</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>return_pred_errors</code></td>
<td><code>bool</code></td>
<td>
<p>Whether to return prediction errors. Defaults to True.</p>
</td>
<td><code>True</code></td>
</tr>
<tr>
<td><code>remove_pred_error_examples</code></td>
<td><code>bool</code></td>
<td>
<p>Whether to remove examples from returned PredictionError. Defaults to True.</p>
</td>
<td><code>True</code></td>
</tr>
</tbody>
</table>
<p><strong>Exceptions:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>ValueError</code></td>
<td>
<p>Each PredictionError must have a List of examples</p>
</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>List[recon.types.HardestExample]</code></td>
<td>
<p>List[HardestExample]: Sorted list of the hardest examples for a model to work on.</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>recon/insights.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">get_hardest_examples</span><span class="p">(</span>
    <span class="n">pred_errors</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">PredictionError</span><span class="p">],</span>
    <span class="n">return_pred_errors</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">remove_pred_error_examples</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">HardestExample</span><span class="p">]:</span>
    <span class="sd">"""Get hardest examples from list of PredictionError types</span>

<span class="sd">    Args:</span>
<span class="sd">        pred_errors (List[PredictionError]): list of PredictionError</span>
<span class="sd">        return_pred_errors (bool, optional): Whether to return prediction errors. Defaults to True.</span>
<span class="sd">        remove_pred_error_examples (bool, optional): Whether to remove examples from returned PredictionError. Defaults to True.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: Each PredictionError must have a List of examples</span>

<span class="sd">    Returns:</span>
<span class="sd">        List[HardestExample]: Sorted list of the hardest examples for a model to work on.</span>
<span class="sd">    """</span>

    <span class="n">has_examples</span> <span class="o">=</span> <span class="nb">any</span><span class="p">([</span><span class="n">pe</span><span class="o">.</span><span class="n">examples</span> <span class="k">for</span> <span class="n">pe</span> <span class="ow">in</span> <span class="n">pred_errors</span><span class="p">])</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">has_examples</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">"Each PredictionError in Parameter pred_errors must have examples attached."</span>
        <span class="p">)</span>

    <span class="n">examples_text_map</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Example</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">example_pred_errors_map</span><span class="p">:</span> <span class="n">DefaultDict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">PredictionError</span><span class="p">]]</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">pe</span> <span class="ow">in</span> <span class="n">pred_errors</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">pe</span><span class="o">.</span><span class="n">examples</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">example</span> <span class="ow">in</span> <span class="n">pe</span><span class="o">.</span><span class="n">examples</span><span class="p">:</span>
                <span class="n">examples_text_map</span><span class="p">[</span><span class="n">example</span><span class="o">.</span><span class="n">original</span><span class="o">.</span><span class="n">text</span><span class="p">]</span> <span class="o">=</span> <span class="n">example</span><span class="o">.</span><span class="n">original</span>
                <span class="n">example_pred_errors_map</span><span class="p">[</span><span class="n">example</span><span class="o">.</span><span class="n">original</span><span class="o">.</span><span class="n">text</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="n">PredictionError</span><span class="p">(</span>
                        <span class="n">text</span><span class="o">=</span><span class="n">pe</span><span class="o">.</span><span class="n">text</span><span class="p">,</span>
                        <span class="n">true_label</span><span class="o">=</span><span class="n">pe</span><span class="o">.</span><span class="n">true_label</span><span class="p">,</span>
                        <span class="n">pred_label</span><span class="o">=</span><span class="n">pe</span><span class="o">.</span><span class="n">pred_label</span><span class="p">,</span>
                        <span class="n">count</span><span class="o">=</span><span class="n">pe</span><span class="o">.</span><span class="n">count</span><span class="p">,</span>
                        <span class="n">examples</span><span class="o">=</span><span class="p">[</span><span class="n">example</span><span class="p">],</span>
                    <span class="p">)</span>
                <span class="p">)</span>

    <span class="n">hardest_examples</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">example_text</span><span class="p">,</span> <span class="n">example_pred_errors</span> <span class="ow">in</span> <span class="n">example_pred_errors_map</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">example</span> <span class="o">=</span> <span class="n">examples_text_map</span><span class="p">[</span><span class="n">example_text</span><span class="p">]</span>  <span class="c1"># type: ignore</span>

        <span class="n">prediction_errors</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">PredictionError</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="n">remove_pred_error_examples</span> <span class="ow">and</span> <span class="n">example_pred_errors</span><span class="p">:</span>
            <span class="n">prediction_errors</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">PredictionError</span><span class="p">(</span>
                    <span class="n">text</span><span class="o">=</span><span class="n">pe</span><span class="o">.</span><span class="n">text</span><span class="p">,</span>
                    <span class="n">true_label</span><span class="o">=</span><span class="n">pe</span><span class="o">.</span><span class="n">true_label</span><span class="p">,</span>
                    <span class="n">pred_label</span><span class="o">=</span><span class="n">pe</span><span class="o">.</span><span class="n">pred_label</span><span class="p">,</span>
                    <span class="n">count</span><span class="o">=</span><span class="n">pe</span><span class="o">.</span><span class="n">count</span><span class="p">,</span>
                    <span class="n">examples</span><span class="o">=</span><span class="p">[],</span>
                <span class="p">)</span>
                <span class="k">for</span> <span class="n">pe</span> <span class="ow">in</span> <span class="n">example_pred_errors</span>
            <span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">prediction_errors</span> <span class="o">=</span> <span class="n">example_pred_errors</span>

        <span class="n">prediction_error_hashes</span><span class="p">:</span> <span class="n">Set</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="n">deduped_prediction_errors</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">PredictionError</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">pe</span> <span class="ow">in</span> <span class="n">prediction_errors</span><span class="p">:</span>
            <span class="n">pe_hash</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">pe</span><span class="o">.</span><span class="n">text</span><span class="si">}</span><span class="s2">||</span><span class="si">{</span><span class="n">pe</span><span class="o">.</span><span class="n">true_label</span><span class="si">}</span><span class="s2">||</span><span class="si">{</span><span class="n">pe</span><span class="o">.</span><span class="n">pred_label</span><span class="si">}</span><span class="s2">"</span>
            <span class="k">if</span> <span class="n">pe_hash</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">prediction_error_hashes</span><span class="p">:</span>
                <span class="n">deduped_prediction_errors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pe</span><span class="p">)</span>

        <span class="n">record</span> <span class="o">=</span> <span class="n">HardestExample</span><span class="p">(</span><span class="n">example</span><span class="o">=</span><span class="n">example</span><span class="p">,</span> <span class="n">count</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">deduped_prediction_errors</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">return_pred_errors</span><span class="p">:</span>
            <span class="n">record</span><span class="o">.</span><span class="n">prediction_errors</span> <span class="o">=</span> <span class="n">deduped_prediction_errors</span>
        <span class="n">hardest_examples</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">record</span><span class="p">)</span>

    <span class="n">sorted_hardest_examples</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">hardest_examples</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">he</span><span class="p">:</span> <span class="n">he</span><span class="o">.</span><span class="n">count</span><span class="p">,</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">sorted_hardest_examples</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h2 class="doc doc-heading" id="recon.insights.get_label_disparities">
<code class="highlight language-python">
get_label_disparities<span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">label1</span><span class="p">,</span> <span class="n">label2</span><span class="p">,</span> <span class="n">case_sensitive</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> </code>
<a class="headerlink" href="#recon.insights.get_label_disparities" title="Permanent link">¶</a></h2>
<div class="doc doc-contents">
<p>Identify annotated spans that have different labels in different examples</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>data</code></td>
<td><code>List[recon.types.Example]</code></td>
<td>
<p>Input List of examples</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>label1</code></td>
<td><code>str</code></td>
<td>
<p>First label to compare</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>label2</code></td>
<td><code>str</code></td>
<td>
<p>Second label to compare</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>case_sensitive</code></td>
<td><code>bool</code></td>
<td>
<p>Consider case of text for each annotation</p>
</td>
<td><code>False</code></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Set[str]</code></td>
<td>
<p>Set[str]: Set of all unique text spans that overlap between label1 and label2</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>recon/insights.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">get_label_disparities</span><span class="p">(</span>
    <span class="n">data</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Example</span><span class="p">],</span> <span class="n">label1</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">label2</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">case_sensitive</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Set</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
    <span class="sd">"""Identify annotated spans that have different labels in different examples</span>

<span class="sd">    Args:</span>
<span class="sd">        data (List[Example]): Input List of examples</span>
<span class="sd">        label1 (str): First label to compare</span>
<span class="sd">        label2 (str): Second label to compare</span>
<span class="sd">        case_sensitive (bool, optional): Consider case of text for each annotation</span>

<span class="sd">    Returns:</span>
<span class="sd">        Set[str]: Set of all unique text spans that overlap between label1 and label2</span>
<span class="sd">    """</span>
    <span class="n">annotations</span> <span class="o">=</span> <span class="n">get_ents_by_label</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">case_sensitive</span><span class="o">=</span><span class="n">case_sensitive</span><span class="p">)</span>
    <span class="k">return</span> <span class="nb">set</span><span class="p">(</span><span class="n">annotations</span><span class="p">[</span><span class="n">label1</span><span class="p">])</span><span class="o">.</span><span class="n">intersection</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">annotations</span><span class="p">[</span><span class="n">label2</span><span class="p">]))</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h2 class="doc doc-heading" id="recon.insights.top_label_disparities">
<code class="highlight language-python">
top_label_disparities<span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">case_sensitive</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dedupe</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> </code>
<a class="headerlink" href="#recon.insights.top_label_disparities" title="Permanent link">¶</a></h2>
<div class="doc doc-contents">
<p>Identify annotated spans that have different labels
in different examples for all label pairs in data.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>data</code></td>
<td><code>List[recon.types.Example]</code></td>
<td>
<p>Input List of examples</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>case_sensitive</code></td>
<td><code>bool</code></td>
<td>
<p>Consider case of text for each annotation</p>
</td>
<td><code>False</code></td>
</tr>
<tr>
<td><code>dedupe</code></td>
<td><code>bool</code></td>
<td>
<p>Whether to deduplicate for table view vs confusion matrix.
False by default for easy confusion matrix display.</p>
</td>
<td><code>False</code></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>List[recon.types.LabelDisparity]</code></td>
<td>
<p>List[LabelDisparity]: List of LabelDisparity objects for each label pair combination
    sorted by the number of disparities between them.</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>recon/insights.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span> 83
 84
 85
 86
 87
 88
 89
 90
 91
 92
 93
 94
 95
 96
 97
 98
 99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">top_label_disparities</span><span class="p">(</span>
    <span class="n">data</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Example</span><span class="p">],</span> <span class="n">case_sensitive</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">dedupe</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">LabelDisparity</span><span class="p">]:</span>
    <span class="sd">"""Identify annotated spans that have different labels</span>
<span class="sd">    in different examples for all label pairs in data.</span>

<span class="sd">    Args:</span>
<span class="sd">        data (List[Example]): Input List of examples</span>
<span class="sd">        case_sensitive (bool, optional): Consider case of text for each annotation</span>
<span class="sd">        dedupe (bool, optional): Whether to deduplicate for table view vs confusion matrix.</span>
<span class="sd">            False by default for easy confusion matrix display.</span>

<span class="sd">    Returns:</span>
<span class="sd">        List[LabelDisparity]: List of LabelDisparity objects for each label pair combination</span>
<span class="sd">            sorted by the number of disparities between them.</span>
<span class="sd">    """</span>
    <span class="n">annotations</span> <span class="o">=</span> <span class="n">get_ents_by_label</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">case_sensitive</span><span class="o">=</span><span class="n">case_sensitive</span><span class="p">)</span>
    <span class="n">label_disparities</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">label1</span> <span class="ow">in</span> <span class="n">annotations</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">label2</span> <span class="ow">in</span> <span class="n">annotations</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">label1</span> <span class="o">!=</span> <span class="n">label2</span><span class="p">:</span>
                <span class="n">intersection</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">annotations</span><span class="p">[</span><span class="n">label1</span><span class="p">])</span><span class="o">.</span><span class="n">intersection</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">annotations</span><span class="p">[</span><span class="n">label2</span><span class="p">]))</span>
                <span class="n">n_disparities</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">intersection</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">n_disparities</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">dedupe</span><span class="p">:</span>
                        <span class="n">input_hash</span> <span class="o">=</span> <span class="s2">"||"</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">sorted</span><span class="p">([</span><span class="n">label1</span><span class="p">,</span> <span class="n">label2</span><span class="p">]))</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">input_hash</span> <span class="o">=</span> <span class="s2">"||"</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">label1</span><span class="p">,</span> <span class="n">label2</span><span class="p">])</span>

                    <span class="n">label_disparities</span><span class="p">[</span><span class="n">input_hash</span><span class="p">]</span> <span class="o">=</span> <span class="n">LabelDisparity</span><span class="p">(</span>
                        <span class="n">label1</span><span class="o">=</span><span class="n">label1</span><span class="p">,</span> <span class="n">label2</span><span class="o">=</span><span class="n">label2</span><span class="p">,</span> <span class="n">count</span><span class="o">=</span><span class="n">n_disparities</span>
                    <span class="p">)</span>

    <span class="k">return</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">label_disparities</span><span class="o">.</span><span class="n">values</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">ld</span><span class="p">:</span> <span class="n">ld</span><span class="o">.</span><span class="n">count</span><span class="p">,</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h2 class="doc doc-heading" id="recon.insights.top_prediction_errors">
<code class="highlight language-python">
top_prediction_errors<span class="p">(</span><span class="n">recognizer</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">exclude_fp</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">exclude_fn</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> </code>
<a class="headerlink" href="#recon.insights.top_prediction_errors" title="Permanent link">¶</a></h2>
<div class="doc doc-contents">
<p>Get a sorted list of examples your model is worst at predicting.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>recognizer</code></td>
<td><code>EntityRecognizer</code></td>
<td>
<p>An instance of EntityRecognizer</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>data</code></td>
<td><code>List[recon.types.Example]</code></td>
<td>
<p>List of annotated Examples</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>labels</code></td>
<td><code>List[str]</code></td>
<td>
<p>List of labels to get errors for.
Defaults to the labels property of <code>recognizer</code>.</p>
</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>n</code></td>
<td><code>int</code></td>
<td>
<p>If set, only use the top n examples from data.</p>
</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>k</code></td>
<td><code>int</code></td>
<td>
<p>If set, return the top k prediction errors, otherwise the whole list.</p>
</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>exclude_fp</code></td>
<td><code>bool</code></td>
<td>
<p>Flag to exclude False Positive errors.</p>
</td>
<td><code>False</code></td>
</tr>
<tr>
<td><code>exclude_fn</code></td>
<td><code>bool</code></td>
<td>
<p>Flag to exclude False Negative errors.</p>
</td>
<td><code>False</code></td>
</tr>
<tr>
<td><code>verbose</code></td>
<td><code>bool</code></td>
<td>
<p>Show verbose output.</p>
</td>
<td><code>False</code></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>List[recon.types.PredictionError]</code></td>
<td>
<p>List[PredictionError]: List of Prediction Errors your model is making, sorted by the
    spans your model has the most trouble with.</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>recon/insights.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">top_prediction_errors</span><span class="p">(</span>
    <span class="n">recognizer</span><span class="p">:</span> <span class="n">EntityRecognizer</span><span class="p">,</span>
    <span class="n">data</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Example</span><span class="p">],</span>
    <span class="n">labels</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">n</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">k</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">exclude_fp</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">exclude_fn</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">PredictionError</span><span class="p">]:</span>
    <span class="sd">"""Get a sorted list of examples your model is worst at predicting.</span>

<span class="sd">    Args:</span>
<span class="sd">        recognizer (EntityRecognizer): An instance of EntityRecognizer</span>
<span class="sd">        data (List[Example]): List of annotated Examples</span>
<span class="sd">        labels (List[str], optional): List of labels to get errors for.</span>
<span class="sd">            Defaults to the labels property of `recognizer`.</span>
<span class="sd">        n (int, optional): If set, only use the top n examples from data.</span>
<span class="sd">        k (int, optional): If set, return the top k prediction errors, otherwise the whole list.</span>
<span class="sd">        exclude_fp (bool, optional): Flag to exclude False Positive errors.</span>
<span class="sd">        exclude_fn (bool, optional): Flag to exclude False Negative errors.</span>
<span class="sd">        verbose (bool, optional): Show verbose output.</span>

<span class="sd">    Returns:</span>
<span class="sd">        List[PredictionError]: List of Prediction Errors your model is making, sorted by the</span>
<span class="sd">            spans your model has the most trouble with.</span>
<span class="sd">    """</span>
    <span class="n">labels_</span> <span class="o">=</span> <span class="n">labels</span> <span class="ow">or</span> <span class="n">recognizer</span><span class="o">.</span><span class="n">labels</span>
    <span class="k">if</span> <span class="n">n</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:</span><span class="n">n</span><span class="p">]</span>

    <span class="n">n_examples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">texts</span> <span class="o">=</span> <span class="p">(</span><span class="n">e</span><span class="o">.</span><span class="n">text</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">data</span><span class="p">)</span>
    <span class="n">anns</span> <span class="o">=</span> <span class="p">(</span><span class="n">e</span><span class="o">.</span><span class="n">spans</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">data</span><span class="p">)</span>

    <span class="n">errors</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="n">defaultdict</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)))</span>  <span class="c1"># type: ignore</span>
    <span class="n">error_examples</span><span class="p">:</span> <span class="n">DefaultDict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">PredictionErrorExamplePair</span><span class="p">]]</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
    <span class="n">n_errors</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">for</span> <span class="n">orig_example</span><span class="p">,</span> <span class="n">pred_example</span><span class="p">,</span> <span class="n">ann</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">recognizer</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">texts</span><span class="p">),</span> <span class="n">anns</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">k</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">n_errors</span> <span class="o">&gt;</span> <span class="n">k</span><span class="p">:</span>
            <span class="k">break</span>

        <span class="n">pred_error_example_pair</span> <span class="o">=</span> <span class="n">PredictionErrorExamplePair</span><span class="p">(</span>
            <span class="n">original</span><span class="o">=</span><span class="n">orig_example</span><span class="p">,</span> <span class="n">predicted</span><span class="o">=</span><span class="n">pred_example</span>
        <span class="p">)</span>

        <span class="n">cand</span> <span class="o">=</span> <span class="nb">set</span><span class="p">([(</span><span class="n">s</span><span class="o">.</span><span class="n">start</span><span class="p">,</span> <span class="n">s</span><span class="o">.</span><span class="n">end</span><span class="p">,</span> <span class="n">s</span><span class="o">.</span><span class="n">label</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">pred_example</span><span class="o">.</span><span class="n">spans</span><span class="p">])</span>
        <span class="n">gold</span> <span class="o">=</span> <span class="nb">set</span><span class="p">([(</span><span class="n">s</span><span class="o">.</span><span class="n">start</span><span class="p">,</span> <span class="n">s</span><span class="o">.</span><span class="n">end</span><span class="p">,</span> <span class="n">s</span><span class="o">.</span><span class="n">label</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">ann</span><span class="p">])</span>

        <span class="n">fp_diff</span> <span class="o">=</span> <span class="n">cand</span> <span class="o">-</span> <span class="n">gold</span>
        <span class="n">fn_diff</span> <span class="o">=</span> <span class="n">gold</span> <span class="o">-</span> <span class="n">cand</span>

        <span class="n">seen</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">fp_diff</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">exclude_fp</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">fp</span> <span class="ow">in</span> <span class="n">fp_diff</span><span class="p">:</span>
                <span class="n">gold_ent</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="k">for</span> <span class="n">ge</span> <span class="ow">in</span> <span class="n">gold</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">fp</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">ge</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">and</span> <span class="n">fp</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">ge</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
                        <span class="n">gold_ent</span> <span class="o">=</span> <span class="n">ge</span>
                        <span class="k">break</span>
                <span class="k">if</span> <span class="n">gold_ent</span><span class="p">:</span>
                    <span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="n">gold_ent</span>
                    <span class="n">text</span> <span class="o">=</span> <span class="n">pred_example</span><span class="o">.</span><span class="n">text</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">]</span>
                    <span class="n">false_label</span> <span class="o">=</span> <span class="n">fp</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
                    <span class="n">errors</span><span class="p">[</span><span class="n">label</span><span class="p">][</span><span class="n">text</span><span class="p">][</span><span class="n">false_label</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
                    <span class="n">error_examples</span><span class="p">[</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">text</span><span class="si">}</span><span class="s2">||</span><span class="si">{</span><span class="n">label</span><span class="si">}</span><span class="s2">||</span><span class="si">{</span><span class="n">false_label</span><span class="si">}</span><span class="s2">"</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                        <span class="n">pred_error_example_pair</span>
                    <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">false_label</span> <span class="o">=</span> <span class="n">fp</span>
                    <span class="n">text</span> <span class="o">=</span> <span class="n">pred_example</span><span class="o">.</span><span class="n">text</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">]</span>
                    <span class="n">errors</span><span class="p">[</span><span class="n">NONE</span><span class="p">][</span><span class="n">text</span><span class="p">][</span><span class="n">false_label</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
                    <span class="n">error_examples</span><span class="p">[</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">text</span><span class="si">}</span><span class="s2">||</span><span class="si">{</span><span class="n">NONE</span><span class="si">}</span><span class="s2">||</span><span class="si">{</span><span class="n">false_label</span><span class="si">}</span><span class="s2">"</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pred_error_example_pair</span><span class="p">)</span>
                <span class="n">n_errors</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="n">seen</span><span class="o">.</span><span class="n">add</span><span class="p">((</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">fn_diff</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">exclude_fn</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">fn</span> <span class="ow">in</span> <span class="n">fn_diff</span><span class="p">:</span>
                <span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="n">fn</span>
                <span class="k">if</span> <span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">seen</span><span class="p">:</span>
                    <span class="n">text</span> <span class="o">=</span> <span class="n">pred_example</span><span class="o">.</span><span class="n">text</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">]</span>
                    <span class="n">errors</span><span class="p">[</span><span class="n">label</span><span class="p">][</span><span class="n">text</span><span class="p">][</span><span class="n">NONE</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
                    <span class="n">error_examples</span><span class="p">[</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">text</span><span class="si">}</span><span class="s2">||</span><span class="si">{</span><span class="n">label</span><span class="si">}</span><span class="s2">||</span><span class="si">{</span><span class="n">NONE</span><span class="si">}</span><span class="s2">"</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pred_error_example_pair</span><span class="p">)</span>
                    <span class="n">n_errors</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="n">ranked_errors_map</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">PredictionError</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="k">for</span> <span class="n">label</span><span class="p">,</span> <span class="n">errors_per_label</span> <span class="ow">in</span> <span class="n">errors</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">error_text</span><span class="p">,</span> <span class="n">error_labels</span> <span class="ow">in</span> <span class="n">errors_per_label</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">error_label</span><span class="p">,</span> <span class="n">count</span> <span class="ow">in</span> <span class="n">error_labels</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="n">pe_hash</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">error_text</span><span class="si">}</span><span class="s2">||</span><span class="si">{</span><span class="n">label</span><span class="si">}</span><span class="s2">||</span><span class="si">{</span><span class="n">error_label</span><span class="si">}</span><span class="s2">"</span>
                <span class="n">ranked_errors_map</span><span class="p">[</span><span class="n">pe_hash</span><span class="p">]</span> <span class="o">=</span> <span class="n">PredictionError</span><span class="p">(</span>
                    <span class="n">text</span><span class="o">=</span><span class="n">error_text</span><span class="p">,</span>
                    <span class="n">true_label</span><span class="o">=</span><span class="n">label</span><span class="p">,</span>
                    <span class="n">pred_label</span><span class="o">=</span><span class="n">error_label</span><span class="p">,</span>
                    <span class="n">count</span><span class="o">=</span><span class="n">count</span><span class="p">,</span>
                    <span class="n">examples</span><span class="o">=</span><span class="n">error_examples</span><span class="p">[</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">error_text</span><span class="si">}</span><span class="s2">||</span><span class="si">{</span><span class="n">label</span><span class="si">}</span><span class="s2">||</span><span class="si">{</span><span class="n">error_label</span><span class="si">}</span><span class="s2">"</span><span class="p">],</span>
                <span class="p">)</span>

    <span class="n">ranked_errors</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">PredictionError</span><span class="p">]</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span>
        <span class="nb">list</span><span class="p">(</span><span class="n">ranked_errors_map</span><span class="o">.</span><span class="n">values</span><span class="p">()),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">error</span><span class="p">:</span> <span class="n">error</span><span class="o">.</span><span class="n">count</span><span class="p">,</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span>  <span class="c1"># type: ignore</span>
    <span class="p">)</span>
    <span class="n">error_texts</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">re</span> <span class="ow">in</span> <span class="n">ranked_errors</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">re</span><span class="o">.</span><span class="n">examples</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">re</span><span class="o">.</span><span class="n">examples</span><span class="p">:</span>
                <span class="n">error_texts</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">e</span><span class="o">.</span><span class="n">original</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>

    <span class="n">error_rate</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">error_texts</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="n">error_summary</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">"N Examples"</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">),</span>
            <span class="s2">"N Errors"</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">ranked_errors</span><span class="p">),</span>
            <span class="s2">"N Error Examples"</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">error_texts</span><span class="p">),</span>
            <span class="s2">"Error Rate"</span><span class="p">:</span> <span class="n">error_rate</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="n">Printer</span><span class="p">()</span>
        <span class="n">msg</span><span class="o">.</span><span class="n">divider</span><span class="p">(</span><span class="s2">"Error Analysis"</span><span class="p">)</span>
        <span class="n">msg</span><span class="o">.</span><span class="n">table</span><span class="p">(</span><span class="n">error_summary</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">ranked_errors</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
</article>
</div>
</div>
</main>
<footer class="md-footer">
<div class="md-footer-nav">
<nav aria-label="Footer" class="md-footer-nav__inner md-grid">
<a class="md-footer-nav__link md-footer-nav__link--prev" href="../hashing/" rel="prev" title="Hashing">
<div class="md-footer-nav__button md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"></path></svg>
</div>
<div class="md-footer-nav__title">
<div class="md-ellipsis">
<span class="md-footer-nav__direction">
                  Previous
                </span>
                Hashing
              </div>
</div>
</a>
<a class="md-footer-nav__link md-footer-nav__link--next" href="../loaders/" rel="next" title="Loaders">
<div class="md-footer-nav__title">
<div class="md-ellipsis">
<span class="md-footer-nav__direction">
                  Next
                </span>
                Loaders
              </div>
</div>
<div class="md-footer-nav__button md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"></path></svg>
</div>
</a>
</nav>
</div>
<div class="md-footer-meta md-typeset">
<div class="md-footer-meta__inner md-grid">
<div class="md-footer-copyright">
        
        Made with
        <a href="https://squidfunk.github.io/mkdocs-material/" rel="noopener" target="_blank">
          Material for MkDocs
        </a>
</div>
<div class="md-footer-social">
</div>
</div>
</div>
</footer>
</div>
<script src="../../assets/javascripts/vendor.d710d30a.min.js"></script>
<script src="../../assets/javascripts/bundle.b39636ac.min.js"></script><script id="__lang" type="application/json">{"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents"}</script>
<script>
        app = initialize({
          base: "../..",
          features: [],
          search: Object.assign({
            worker: "../../assets/javascripts/worker/search.a68abb33.min.js"
          }, typeof search !== "undefined" && search)
        })
      </script>
<script src="../../js/termynal.js"></script>
<script src="https://unpkg.com/mermaid@8.4.6/dist/mermaid.min.js"></script>
<script src="../../js/custom.js"></script>
</body>
</html>